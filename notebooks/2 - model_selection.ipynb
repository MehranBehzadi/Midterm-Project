{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1968, 23)\n",
      "X_test shape: (492, 23)\n",
      "y_train shape: (1968,)\n",
      "y_test shape: (492,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Load preprocessed data\n",
    "file_path = os.path.join('..', 'data', 'processed', 'preprocessed_data.csv')\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define target and features\n",
    "target_column = 'list_price'  # or another target column if different\n",
    "y = data[target_column]\n",
    "X = data.drop(columns=[target_column])\n",
    "\n",
    "# Ensure that the 'city', 'state', and 'type' columns are excluded from the features\n",
    "X = X.drop(columns=['city', 'state', 'type', 'sold_date', 'tags', 'filtered_tags'])\n",
    "\n",
    "# Split data into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Mean Absolute Error\n",
      "0       Linear Regression         12589.039777\n",
      "1  Support Vector Machine         77841.204215\n",
      "2           Random Forest          9256.975018\n",
      "3                 XGBoost         10601.229121\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values in features (X)\n",
    "X_imputer = SimpleImputer(strategy='mean')  # or strategy='median'\n",
    "X_train_imputed = X_imputer.fit_transform(X_train)\n",
    "X_test_imputed = X_imputer.transform(X_test)\n",
    "\n",
    "# Impute missing values in target (y)\n",
    "y_imputer = SimpleImputer(strategy='mean')  # or strategy='median'\n",
    "y_train_imputed = y_imputer.fit_transform(y_train.values.reshape(-1, 1)).ravel()  # Flatten to 1D array\n",
    "y_test_imputed = y_imputer.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Support Vector Machine': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'XGBoost': xgb.XGBRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_imputed, y_train_imputed)\n",
    "    y_pred = model.predict(X_test_imputed)\n",
    "    mae = mean_absolute_error(y_test_imputed, y_pred)  # You can also use other metrics like RMSE or R2\n",
    "    results[model_name] = mae\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Mean Absolute Error'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "the_one",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
